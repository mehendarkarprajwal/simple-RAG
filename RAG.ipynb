{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4716e93f-42ec-4e01-8c38-fa97471eec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.16-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.16 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.16.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.4-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (6.0.2)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.38-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading aiohttp-3.11.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading numpy-2.2.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pydantic>=2.8.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.11-py3-none-any.whl.metadata (912 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
      "Collecting pandas (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pypdf-5.2.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting click (from nltk>3.8.1->llama-index)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Collecting certifi<2025.0.0,>=2024.7.4 (from llama-cloud<0.2.0,>=0.1.8->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.16->llama-index) (0.14.0)\n",
      "Collecting llama-cloud-services (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading jiter-0.8.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.16->llama-index) (2.3.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading llama_index-0.12.16-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.12.16.post1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.4-py3-none-any.whl (39 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading aiohttp-3.11.12-cp311-cp311-macosx_11_0_arm64.whl (455 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading llama_cloud-0.1.11-py3-none-any.whl (250 kB)\n",
      "Downloading llama_parse-0.6.0-py3-none-any.whl (4.8 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
      "Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-5.2.0-py3-none-any.whl (298 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.4/982.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading numpy-2.2.2-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl (52 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl (272 kB)\n",
      "Downloading jiter-0.8.2-cp311-cp311-macosx_11_0_arm64.whl (311 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl (92 kB)\n",
      "Downloading llama_cloud_services-0.6.0-py3-none-any.whl (22 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: striprtf, pytz, filetype, dirtyjson, wrapt, tzdata, tqdm, tenacity, SQLAlchemy, regex, python-dotenv, pypdf, pydantic-core, propcache, pillow, numpy, networkx, mypy-extensions, multidict, marshmallow, joblib, jiter, greenlet, fsspec, frozenlist, distro, click, certifi, annotated-types, aiohappyeyeballs, yarl, typing-inspect, pydantic, pandas, nltk, deprecated, aiosignal, tiktoken, dataclasses-json, aiohttp, openai, llama-index-core, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "Successfully installed SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.4 aiohttp-3.11.12 aiosignal-1.3.2 annotated-types-0.7.0 certifi-2024.12.14 click-8.1.8 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 filetype-1.2.0 frozenlist-1.5.0 fsspec-2025.2.0 greenlet-3.1.1 jiter-0.8.2 joblib-1.4.2 llama-cloud-0.1.11 llama-cloud-services-0.6.0 llama-index-0.12.16 llama-index-agent-openai-0.4.3 llama-index-cli-0.4.0 llama-index-core-0.12.16.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-llms-openai-0.3.18 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.4 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.0 marshmallow-3.26.1 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nltk-3.9.1 numpy-2.2.2 openai-1.61.1 pandas-2.2.3 pillow-11.1.0 propcache-0.2.1 pydantic-2.10.6 pydantic-core-2.27.2 pypdf-5.2.0 python-dotenv-1.0.1 pytz-2025.1 regex-2024.11.6 striprtf-0.0.26 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.1 typing-inspect-0.9.0 tzdata-2025.1 wrapt-1.17.2 yarl-1.18.3\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.5.1-py3-none-any.whl.metadata (767 bytes)\n",
      "Collecting huggingface-hub>=0.19.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.12.16.post1)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.12)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.38)\n",
      "Requirement already satisfied: dataclasses-json in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.6.0-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.18.3)\n",
      "Requirement already satisfied: click in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.5)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: anyio in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Downloading llama_index_embeddings_huggingface-0.5.1-py3-none-any.whl (8.9 kB)\n",
      "Using cached huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading torch-2.6.0-cp311-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl (24.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl (408 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed filelock-3.17.0 huggingface-hub-0.28.1 llama-index-embeddings-huggingface-0.5.1 mpmath-1.3.0 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.1 sentence-transformers-3.4.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 transformers-4.48.3\n",
      "Collecting llama-index-llms-gemini\n",
      "  Downloading llama_index_llms_gemini-0.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting google-generativeai>=0.5.2 (from llama-index-llms-gemini)\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.12 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-llms-gemini) (0.12.16.post1)\n",
      "Collecting pillow<11.0.0,>=10.2.0 (from llama-index-llms-gemini)\n",
      "  Downloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading google_api_python_client-2.160.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting protobuf (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pydantic in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.10.6)\n",
      "Requirement already satisfied: tqdm in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.18.3)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading googleapis_common_protos-1.67.0rc1-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: click in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.26.1)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: anyio in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.14.0)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (24.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.3.1)\n",
      "Downloading llama_index_llms_gemini-0.4.7-py3-none-any.whl (7.6 kB)\n",
      "Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading google_api_python_client-2.160.0-py2.py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "Downloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.67.0rc1-py2.py3-none-any.whl (165 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.70.0-cp311-cp311-macosx_10_14_universal2.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, protobuf, pillow, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, llama-index-llms-gemini\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "Successfully installed cachetools-5.5.1 google-ai-generativelanguage-0.6.15 google-api-core-2.24.1 google-api-python-client-2.160.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.4 googleapis-common-protos-1.67.0rc1 grpcio-1.70.0 grpcio-status-1.70.0 httplib2-0.22.0 llama-index-llms-gemini-0.4.7 pillow-10.4.0 proto-plus-1.26.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.1 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-index-llms-gemini\n",
    "!pip install -q llama-index google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce8f5ed-188d-4c5a-997b-5492da0a2424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prajwalbmehendarkar/miniconda3/envs/aix_rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core import Settings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7fedd9-a48a-4c83-a724-3c95ec49cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"Put your Google API key here\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# Setting global parameter\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") # set the embedding model\n",
    "Settings.llm = Gemini(model_name=\"models/gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e93269-377c-45eb-95ce-e79f7e7a1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(input_files=['commands_pdf.pdf']).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af583575-3630-4adf-a93a-4e74349e3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=10)\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.text_splitter = text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1713dcb-bc4d-4c9f-b9fa-b93d5b004475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, transformations=[text_splitter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9214b8c7-32d5-4575-a5c1-0ab78e63843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"blogs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cddbf6a3-53aa-4abb-b28c-78e756705e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "# storage_context = StorageContext.from_defaults(persist_dir=\"blogs/\")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"/Users/prajwalbmehendarkar/Documents/rag_blogs/blogs\")\n",
    "\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14aa495c-598f-4e85-a7d5-4d327ef3b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a knowledgeable and precise assistant specialized in question-answering tasks, \n",
    "particularly from academic and research-based sources. \n",
    "Your goal is to provide accurate, concise, and contextually relevant answers based on the given information.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Comprehension and Accuracy: Carefully read and comprehend the provided context from the research paper to ensure accuracy in your response.\n",
    "Conciseness: Deliver the answer in no more than three sentences, ensuring it is concise and directly addresses the question.\n",
    "Truthfulness: If the context does not provide enough information to answer the question, clearly state, \"I don't know.\"\n",
    "Contextual Relevance: Ensure your answer is well-supported by the retrieved context and does not include any information beyond what is provided.\n",
    "\n",
    "Remember if no context is provided please say you don't know the answer\n",
    "Here is the question and context for you to work with:\n",
    "\n",
    "\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\"\n",
    "\n",
    "\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "prompt_tmpl = PromptTemplate(\n",
    "    template=template,\n",
    "    template_var_mappings={\"query_str\": \"question\", \"context_str\": \"context\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0b8d76-93f4-4b18-88a9-02a952a180af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\":prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c695469-e028-4955-80d8-0ebf795b4db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To set the access control information for the status file with information stored in the acldefs file, enter:\n",
      "\n",
      "aclput -i acldefs status\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\" Whats the command To set the access control information for the status file with information stored in the acldefs file \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fdbb61-2754-4bf1-a460-71baac93b799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To set the access control information for the status file with the same information used for the plans file, enter:\n",
      "\n",
      "aclget plans | aclput status\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\" Whats the command  To set the access control information for the status file with the same information used for the plans file, enter \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "002f18e6-477b-44a9-87bc-9c9800c65101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To start the test.c file with a release number of 3.1, use the -r flag with the admin command, as shown below:\n",
      "\n",
      "$ admin -itest.c -r3 s.test.c\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\" Whats the command To start the test.c file with a release number of 3.1, use the -r flag with the admin command\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f3db76-e05b-4c62-bfb2-a30b8eb46c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The command to write all of the high-level security options to an output file is:\n",
      "aixpert -l h -n -o /etc/security/aixpert/core/hls.xml\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\" Whats the command To write all of the high-level security options to an output file\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4e77c0d-0685-45eb-8230-32187489dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To install a mksysb image on hdisk3 and hdisk4, then run a customized script (/tmp/script) to copy some user files over to the alternate rootvg file systems before reboot:\n",
      "\n",
      "alt_disk_mksysb -m /mksysb_images/my_mksysb -d \"hdisk3 hdisk4\" -s /tmp/script\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\" Whats the command To install a mksysb image on hdisk3 and hdisk4 , then run a customized script (/tmp/script) to copy some user files over to the alternate rootvg file systems before reboot\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1feeb2d8-ae66-474e-acb9-4b4cc7e15cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To install a mksysb image on hdisk1, and to convert the file system from a JFS file system to a JFS2 file system, run the following command:\n",
      "\n",
      "alt_disk_mksysb -B -T -m  /mksysb_images/my_mksysb -d hdisk1\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\" Whats the command To install a mksysb image on hdisk1, and to convert the file system from a JFS file system to a JFS2 file system\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d089b31-72b7-4f4d-937c-8b271610cb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a knowledgeable and precise assistant specialized in question-answering tasks, particularly from academic and research-based sources. My goal is to provide accurate, concise, and contextually relevant answers based on the given information.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who are you\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234406ed-aceb-4ac1-9718-f63b767a0eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
